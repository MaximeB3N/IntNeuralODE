{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import lars_path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from src.models.ae import ConvAE, Decoder, Encoder\n",
    "from src.models.anode import ANODENet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvNodeWithBatch(nn.Module):\n",
    "    def __init__(self, device, size, latent_dim, in_channels,\n",
    "    ode_hidden_dim, ode_out_dim, augment_dim=0, time_dependent=False, \n",
    "    ode_non_linearity='relu', conv_activation=nn.ReLU(),latent_activation=None, stack_size=1):\n",
    "        super(ConvNodeWithBatch, self).__init__()\n",
    "        self.device = device\n",
    "        self.size = size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_activation = conv_activation\n",
    "        self.latent_activation = latent_activation\n",
    "        self.ode_hidden_dim = ode_hidden_dim\n",
    "        self.out_dim = ode_out_dim\n",
    "        self.augment_dim = augment_dim\n",
    "        self.time_dependent = time_dependent\n",
    "        self.ode_non_linearity = ode_non_linearity\n",
    "\n",
    "        print(\"-\"*50)\n",
    "        print(\"Creating ConvAE...\")\n",
    "        self.encoder = TimeDistributed(\n",
    "            Encoder(device=device, latent_dim=latent_dim, in_channels=in_channels,\n",
    "            activation=conv_activation, relu=latent_activation).to(device), \n",
    "            len_shape_without_batch=4, # input without batch are (times, channels, height, width)\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.decoder = TimeDistributed(\n",
    "            Decoder(device=device, latent_dim=latent_dim, in_channels=in_channels,\n",
    "            activation=conv_activation).to(device),\n",
    "            len_shape_without_batch=2, # input without batch are (times, latent_dim)\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        print(\"-\"*50)\n",
    "        print(\"Creating ANODENet...\")\n",
    "        self.node = ANODENet(device, latent_dim*(stack_size + 1), ode_hidden_dim, ode_out_dim, augment_dim, time_dependent=False,\n",
    "            non_linearity=ode_non_linearity).to(device)\n",
    "\n",
    "    def forward(self, images, times, dt):\n",
    "        # images: [(batch), n_stack, in_channels, height, width]\n",
    "        # latent_z: [n_stack, latent_dim]\n",
    "        # print(\"input_images: \", images.shape)\n",
    "        latent_z = self.encoder(images)\n",
    "        # print(\"latent_z: \", latent_z.shape)\n",
    "        \n",
    "        # latent_z_stack: [(batch), n_stack, latent_dim*(n_stack+1)]\n",
    "        # for the moment n_stack = 1\n",
    "        if len(latent_z.shape) == 3:\n",
    "            latent_z_stack = torch.cat([latent_z[:, :-1], (latent_z[:, 1:]-latent_z[:, :-1])/dt], dim=-1).squeeze(1)\n",
    "        \n",
    "\n",
    "        elif len(latent_z.shape) == 2:\n",
    "            latent_z_stack = torch.cat([latent_z[:-1], (latent_z[1:]-latent_z[:-1])/dt], dim=-1)\n",
    "\n",
    "        # print(\"latent_z_stack: \", latent_z_stack.shape)\n",
    "\n",
    "        # sim : [times, (batch),ode_out_dim]\n",
    "        sim = self.node(latent_z_stack, times)[..., :latent_z.shape[-1]]\n",
    "        # print(\"sim: \", sim.shape)\n",
    "        # sim : [(batch), n_stack, ode_out_dim]\n",
    "        if len(images.shape) == 5:\n",
    "            sim = sim.swapdims(0,1)\n",
    "        else:\n",
    "            sim = sim.squeeze(1)\n",
    "        # print(\"sim: \", sim.shape)\n",
    "\n",
    "        reconstructed_images = self.decoder(sim)\n",
    "        # print(\"reconstructed_images: \", reconstructed_images.shape)\n",
    "\n",
    "        return reconstructed_images, sim\n",
    "\n",
    "\n",
    "\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module, len_shape_without_batch, batch_first=False):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "        self._len_shape_without_batch = len_shape_without_batch\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, time, *]\n",
    "        assert len(x.shape) == self._len_shape_without_batch or self._len_shape_without_batch + 1, f\"Input must have shape {self._len_shape_without_batch}D or {self._len_shape_without_batch + 1}D, received {len(x.shape)}D\"\n",
    "\n",
    "        if len(x.size()) == self._len_shape_without_batch:\n",
    "            return self.module(x)\n",
    "\n",
    "        batch_flatten_shapes = list(x.shape[1:])\n",
    "        batch_flatten_shapes[0] = -1\n",
    "        # Squash samples and timesteps into a single axis\n",
    "        x_reshape = x.contiguous().reshape(batch_flatten_shapes)  # (samples * timesteps, input_size)\n",
    "        # print(\"TimeDistributed: x_reshape: \", x_reshape.shape)\n",
    "        y = self.module(x_reshape)\n",
    "        # print(\"TimeDistributed: y: \", y.shape)\n",
    "\n",
    "        # We have to reshape Y\n",
    "        \n",
    "        if self.batch_first:\n",
    "            final_shapes = [x.shape[0], -1] + list(y.shape[1:])\n",
    "            y = y.contiguous().view(final_shapes)  # (samples, timesteps, output_size)\n",
    "        else:\n",
    "            final_shapes = [-1, x.shape[1]] + list(y.shape[1:])\n",
    "            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n",
    "        # print(\"TimeDistributed: y return: \", y.shape)\n",
    "\n",
    "\n",
    "        # print('TimeDistributed: y return: ', y.shape)    \n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Creating ConvAE...\n",
      "Number of parameters in the encoder model: 127568\n",
      "Number of parameters in the decoder model: 127715\n",
      "--------------------------------------------------\n",
      "Creating ANODENet...\n",
      "Number of parameters in the model: 25392\n"
     ]
    }
   ],
   "source": [
    "model = ConvNodeWithBatch(device='cpu', size=28, latent_dim=16, in_channels=3,\n",
    "    ode_hidden_dim=128, ode_out_dim=16, augment_dim=0, time_dependent=False,\n",
    "    ode_non_linearity='relu', conv_activation=nn.ReLU(),latent_activation=None, stack_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684, 0.4211,\n",
      "        0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895, 0.8421, 0.8947,\n",
      "        0.9474, 1.0000])\n",
      "2 torch.Size([10, 20, 3, 28, 28]) torch.Size([10, 20, 16])\n"
     ]
    }
   ],
   "source": [
    "input_test_2 = torch.randn(10, 2, 3, 28, 28)\n",
    "times = torch.linspace(0, 1, 20)\n",
    "print(times)\n",
    "res1 = model(input_test_2, times, 1./20)\n",
    "print(len(res1), res1[0].shape, res1[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 torch.Size([20, 3, 28, 28]) torch.Size([20, 16])\n"
     ]
    }
   ],
   "source": [
    "input_test = torch.randn(2, 3, 28, 28)\n",
    "res2 = model(input_test, times, 1./17)\n",
    "print(len(res2), res2[0].shape, res2[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
