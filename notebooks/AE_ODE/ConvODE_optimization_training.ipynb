{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import lars_path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from src.models.ae import ConvAE, Decoder, Encoder\n",
    "from src.models.anode import ANODENet\n",
    "\n",
    "from src.data.box import GravityHoleBall\n",
    "from src.data.generate import generate_gravity_hole_ball_images\n",
    "\n",
    "from src.utils.utils import add_spatial_encoding\n",
    "from src.utils.node import  BatchGetterMultiImages, train_convnode, train_convnode_with_batch\n",
    "from src.utils.viz import  display_convnode_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvNodeWithBatch(nn.Module):\n",
    "    def __init__(self, device, size, latent_dim, in_channels,\n",
    "    ode_hidden_dim, ode_out_dim, augment_dim=0, time_dependent=False, \n",
    "    ode_non_linearity='relu', conv_activation=nn.ReLU(),latent_activation=None, stack_size=1):\n",
    "        super(ConvNodeWithBatch, self).__init__()\n",
    "        self.device = device\n",
    "        self.size = size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_activation = conv_activation\n",
    "        self.latent_activation = latent_activation\n",
    "        self.ode_hidden_dim = ode_hidden_dim\n",
    "        self.out_dim = ode_out_dim\n",
    "        self.augment_dim = augment_dim\n",
    "        self.time_dependent = time_dependent\n",
    "        self.ode_non_linearity = ode_non_linearity\n",
    "\n",
    "        print(\"-\"*50)\n",
    "        print(\"Creating ConvAE...\")\n",
    "        self.encoder = TimeDistributed(\n",
    "            Encoder(device=device, latent_dim=latent_dim, in_channels=in_channels,\n",
    "            activation=conv_activation, relu=latent_activation).to(device), \n",
    "            len_shape_without_batch=4, # input without batch are (times, channels, height, width)\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.decoder = TimeDistributed(\n",
    "            Decoder(device=device, latent_dim=latent_dim, in_channels=in_channels,\n",
    "            activation=conv_activation).to(device),\n",
    "            len_shape_without_batch=2, # input without batch are (times, latent_dim)\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        print(\"-\"*50)\n",
    "        print(\"Creating ANODENet...\")\n",
    "        self.node = ANODENet(device, latent_dim*(stack_size + 1), ode_hidden_dim, ode_out_dim, augment_dim, time_dependent=False,\n",
    "            non_linearity=ode_non_linearity).to(device)\n",
    "\n",
    "    def forward(self, images, times, dt):\n",
    "        # images: [(batch), n_stack, in_channels, height, width]\n",
    "        # latent_z: [n_stack, latent_dim]\n",
    "        # print(\"input_images: \", images.shape)\n",
    "        latent_z = self.encoder(images)\n",
    "        # print(\"latent_z: \", latent_z.shape)\n",
    "        \n",
    "        # latent_z_stack: [(batch), n_stack, latent_dim*(n_stack+1)]\n",
    "        # for the moment n_stack = 1\n",
    "        if len(latent_z.shape) == 3:\n",
    "            latent_z_stack = torch.cat([latent_z[:, :-1], (latent_z[:, 1:]-latent_z[:, :-1])/dt], dim=-1).squeeze(1)\n",
    "        \n",
    "\n",
    "        elif len(latent_z.shape) == 2:\n",
    "            latent_z_stack = torch.cat([latent_z[:-1], (latent_z[1:]-latent_z[:-1])/dt], dim=-1)\n",
    "\n",
    "        # print(\"latent_z_stack: \", latent_z_stack.shape)\n",
    "\n",
    "        # sim : [times, (batch),ode_out_dim]\n",
    "        sim = self.node(latent_z_stack, times)[..., :latent_z.shape[-1]]\n",
    "        # print(\"sim: \", sim.shape)\n",
    "        # sim : [(batch), n_stack, ode_out_dim]\n",
    "        if len(images.shape) == 5:\n",
    "            sim = sim.swapdims(0,1)\n",
    "        else:\n",
    "            sim = sim.squeeze(1)\n",
    "        # print(\"sim: \", sim.shape)\n",
    "\n",
    "        reconstructed_images = self.decoder(sim)\n",
    "        # print(\"reconstructed_images: \", reconstructed_images.shape)\n",
    "\n",
    "        return reconstructed_images, sim\n",
    "\n",
    "    def encode(self, images):\n",
    "\n",
    "        return self.encoder(images)\n",
    "\n",
    "    def decode(self, latent_z):\n",
    "        return self.decoder(latent_z)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module, len_shape_without_batch, batch_first=False):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "        self._len_shape_without_batch = len_shape_without_batch\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, time, *]\n",
    "        assert len(x.shape) == self._len_shape_without_batch or self._len_shape_without_batch + 1, f\"Input must have shape {self._len_shape_without_batch}D or {self._len_shape_without_batch + 1}D, received {len(x.shape)}D\"\n",
    "\n",
    "        if len(x.size()) == self._len_shape_without_batch:\n",
    "            return self.module(x)\n",
    "\n",
    "        batch_flatten_shapes = list(x.shape[1:])\n",
    "        batch_flatten_shapes[0] = -1\n",
    "        # Squash samples and timesteps into a single axis\n",
    "        x_reshape = x.contiguous().reshape(batch_flatten_shapes)  # (samples * timesteps, input_size)\n",
    "        # print(\"TimeDistributed: x_reshape: \", x_reshape.shape)\n",
    "        y = self.module(x_reshape)\n",
    "        # print(\"TimeDistributed: y: \", y.shape)\n",
    "\n",
    "        # We have to reshape Y\n",
    "        \n",
    "        if self.batch_first:\n",
    "            final_shapes = [x.shape[0], -1] + list(y.shape[1:])\n",
    "            y = y.contiguous().view(final_shapes)  # (samples, timesteps, output_size)\n",
    "        else:\n",
    "            final_shapes = [-1, x.shape[1]] + list(y.shape[1:])\n",
    "            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n",
    "        # print(\"TimeDistributed: y return: \", y.shape)\n",
    "\n",
    "\n",
    "        # print('TimeDistributed: y return: ', y.shape)    \n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Creating ConvAE...\n",
      "Number of parameters in the encoder model: 137945\n",
      "Number of parameters in the decoder model: 138083\n",
      "--------------------------------------------------\n",
      "Creating ANODENet...\n",
      "Number of parameters in the model: 30765\n"
     ]
    }
   ],
   "source": [
    "conv_ode = ConvNodeWithBatch(device='cpu', size=28, latent_dim=25, in_channels=3,\n",
    "    ode_hidden_dim=128, ode_out_dim=25, augment_dim=0, time_dependent=False,\n",
    "    ode_non_linearity='relu', conv_activation=nn.ReLU(),latent_activation=None, stack_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684, 0.4211,\n",
      "        0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895, 0.8421, 0.8947,\n",
      "        0.9474, 1.0000])\n",
      "2 torch.Size([10, 20, 3, 28, 28]) torch.Size([10, 20, 25])\n"
     ]
    }
   ],
   "source": [
    "input_test_2 = torch.randn(10, 2, 3, 28, 28)\n",
    "times = torch.linspace(0, 1, 20)\n",
    "print(times)\n",
    "res1 = conv_ode(input_test_2, times, 1./20)\n",
    "print(len(res1), res1[0].shape, res1[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 torch.Size([20, 3, 28, 28]) torch.Size([20, 25])\n"
     ]
    }
   ],
   "source": [
    "input_test = torch.randn(2, 3, 28, 28)\n",
    "res2 = conv_ode(input_test, times, 1./17)\n",
    "print(len(res2), res2[0].shape, res2[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Generating images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30100, 1, 28, 28)\n",
      "torch.Size([100, 301, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "MARGIN_MIN = 5\n",
    "MIN_INIT_VELOCITY = 200.\n",
    "WIDTH, HEIGHT = 28, 28\n",
    "RADIUS = 3\n",
    "\n",
    "infos = {\n",
    "    \"MARGIN_MIN\":MARGIN_MIN,\n",
    "    \"MIN_INIT_VELOCITY\":MIN_INIT_VELOCITY,\n",
    "    \"WIDTH\":WIDTH,\n",
    "    \"HEIGHT\":HEIGHT,\n",
    "    \"RADIUS\":RADIUS\n",
    "}\n",
    "\n",
    "x = WIDTH/4.\n",
    "y = HEIGHT/4.\n",
    "vx = 0.\n",
    "vy = 0.\n",
    "\n",
    "box = GravityHoleBall(x, y, vx, vy, (WIDTH, HEIGHT),RADIUS)\n",
    "\n",
    "\n",
    "Num_pos_velocity = 1\n",
    "N = 100\n",
    "N_frames = 300 + Num_pos_velocity\n",
    "dt = 1./N_frames\n",
    "\n",
    "times = np.arange(0, N_frames*dt, dt)\n",
    "\n",
    "# encoded_trajectory = generate_gravity_hole_ball_positions(box, N=N, N_frames=N_frames, dt=dt)[:,:,:]\n",
    "# print(encoded_trajectory.shape)\n",
    "print(\"-\"*50)\n",
    "print(\"Generating images...\")\n",
    "images = generate_gravity_hole_ball_images(box, N=N, N_frames=N_frames, dt=dt, infos=infos).reshape(-1, 1, HEIGHT, WIDTH)\n",
    "print(images.shape)\n",
    "# dataset = [(image, 0) for image in dataset]\n",
    "# dataset = add_spatial_encoding(dataset)\n",
    "# print(len(dataset), len(dataset[0]), dataset[0][0].shape)\n",
    "images = torch.from_numpy(add_spatial_encoding(images)).float().reshape(N, -1, 3, HEIGHT, WIDTH)\n",
    "print(images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 16\n",
    "batch_time = 200\n",
    "n_stack = 1\n",
    "total_length = N_frames - Num_pos_velocity\n",
    "# batch_size = 64\n",
    "\n",
    "class BatchGetterMultiImages:\n",
    "    def __init__(self, batch_time, batch_size, n_stack, total_length, dt, images, frac_train):\n",
    "        # N: number of trajectories\n",
    "        # M: number of time steps\n",
    "        # D: dimension of the state space\n",
    "        # positions: (N, T, D)\n",
    "        self.times = torch.linspace(0., total_length*dt, total_length, dtype=torch.float64).float()\n",
    "        if isinstance(images, torch.Tensor):\n",
    "            self.true_images = images.float()\n",
    "\n",
    "        elif isinstance(images, np.ndarray):\n",
    "            self.true_images = torch.from_numpy(images).float()\n",
    "\n",
    "        else:\n",
    "            assert False, \"positions must be either a torch.Tensor or a np.ndarray\"\n",
    "\n",
    "        self.N_train = int(images.shape[0]*frac_train)\n",
    "\n",
    "        self.train_times = self.times #[:self.N_train]\n",
    "        self.test_times = self.times #[self.N_train:]\n",
    "        self.train_images = self.true_images[:self.N_train]\n",
    "        self.test_images = self.true_images[self.N_train:]\n",
    "        self.batch_size = batch_size\n",
    "        self.n_stack = n_stack\n",
    "        self.batch_time = batch_time\n",
    "        self.dt = dt\n",
    "        self.total_length = total_length\n",
    "\n",
    "    def get_batch(self):\n",
    "        index = np.random.randint(0, self.N_train, self.batch_size)\n",
    "        s = torch.from_numpy(np.random.choice(np.arange(self.train_times.shape[0] - self.batch_time, dtype=np.int64), 1, replace=False))\n",
    "        batch_y0 = self.train_images[index, s:s+self.n_stack+1].squeeze(0) # (M, D)\n",
    "        batch_t = self.train_times[:self.batch_time]  # (T)\n",
    "        batch_y = torch.stack([self.train_images[index, s + i] for i in range(self.batch_time)], dim=1).squeeze(1)  # (T, M, D)\n",
    "        return batch_y0, batch_t, batch_y\n",
    "\n",
    "getter = BatchGetterMultiImages(batch_time, batch_size, n_stack, total_length, dt, images, frac_train=1.)\n",
    "\n",
    "optimizer = torch.optim.Adam(conv_ode.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2000, gamma=0.9)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2, 3, 28, 28]) torch.Size([200]) torch.Size([16, 200, 3, 28, 28])\n",
      "2 torch.Size([16, 200, 3, 28, 28]) torch.Size([16, 200, 25])\n"
     ]
    }
   ],
   "source": [
    "sample = getter.get_batch()\n",
    "print(sample[0].shape, sample[1].shape, sample[2].shape)\n",
    "res1 = conv_ode(sample[0], sample[1], 1./total_length)\n",
    "print(len(res1), res1[0].shape, res1[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/3000 [00:07<38:06,  1.31it/s, Loss: 0.01467174]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/01/nfq6qhcj2j7dqfld6ps6vhbc0000gn/T/ipykernel_3417/1709349518.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_display\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdisplay_convnode_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_display\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# train_convnode(conv_ode, optimizer, scheduler, epochs, 1, getter, display=100, loss_fn=None, display_results_fn=display_fn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_convnode_with_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_ode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_results_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/X/3A/Stage/IntNeuralODE/src/utils/node.py\u001b[0m in \u001b[0;36mtrain_convnode_with_batch\u001b[0;34m(model, optimizer, scheduler, epochs, getter, display, loss_fn, display_results_fn, out_display)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mbatch_init_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_true_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# compute the output of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mout_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_init_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;31m# compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# print(out.shape, out.view(-1, batch_init_positions.shape[-1]).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/01/nfq6qhcj2j7dqfld6ps6vhbc0000gn/T/ipykernel_3417/3508664572.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, times, dt)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# print(\"sim: \", sim.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mreconstructed_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;31m# print(\"reconstructed_images: \", reconstructed_images.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/01/nfq6qhcj2j7dqfld6ps6vhbc0000gn/T/ipykernel_3417/3508664572.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mx_reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_flatten_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (samples * timesteps, input_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# print(\"TimeDistributed: x_reshape: \", x_reshape.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;31m# print(\"TimeDistributed: y: \", y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/X/3A/Stage/IntNeuralODE/src/models/ae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, latent)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;31m# print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    914\u001b[0m             input, output_size, self.stride, self.padding, self.kernel_size, self.dilation)  # type: ignore[arg-type]\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         return F.conv_transpose2d(\n\u001b[0m\u001b[1;32m    917\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m             output_padding, self.groups, self.dilation)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 3000\n",
    "root = None #\"images/AE_ODE/Gravity/MultiTrajectories/Together/\"\n",
    "name = None # \"conv_ode_1_ball_latent_{}_hidden_ode_{}_stack_{}_conv_activation_{}\".format(latent_dim, ode_hidden_dim, stack_size, conv_activation)\n",
    "display_fn = lambda i, model, out_display, getter, final_time, dt: display_convnode_trajectory(i, model, out_display, getter, final_time, dt, root=root, name=name)\n",
    "# train_convnode(conv_ode, optimizer, scheduler, epochs, 1, getter, display=100, loss_fn=None, display_results_fn=display_fn)\n",
    "train_convnode_with_batch(conv_ode, optimizer, scheduler, epochs, getter, display=100, loss_fn=None, display_results_fn=display_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
