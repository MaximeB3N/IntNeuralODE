{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary\n",
    "import numpy as np\n",
    "import plotly\n",
    "from PIL import Image\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "from ipywidgets import interact\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from src.data.box import GravityHoleBall\n",
    "from src.data.generate import generate_gravity_hole_ball_images\n",
    "\n",
    "from src.utils.utils import add_spatial_encoding\n",
    "from src.utils.node import  BatchGetterMultiImages, train_convnode_with_batch, train_convnode_with_batch_and_latent_supervision\n",
    "from src.utils.viz import  display_convnode_trajectory\n",
    "\n",
    "from src.models.convnode import ConvNodeWithBatch, ResNodeWithBatch#, LatentRegularizerLoss\n",
    "from src.models.resnet import ResNetCustomEncoder, ResNetCustomDecoder\n",
    "from src.models.anode import ANODENet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For 28x28 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Generating images...\n",
      "(10000, 20, 28, 28) 1.0 0.0\n",
      "(200000, 1, 28, 28)\n",
      "torch.Size([8000, 20, 3, 28, 28]) torch.Size([2000, 20, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "MARGIN_MIN = 7\n",
    "MIN_INIT_VELOCITY = 1000.\n",
    "WIDTH, HEIGHT = 28, 28\n",
    "RADIUS = 3\n",
    "size = WIDTH\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"Generating images...\")\n",
    "images = np.load(\"data/movingmnist_dataset_10000_20_1_28_2/sequences.npy\").swapaxes(-1, -2)\n",
    "# Apply the sigmoid function to the images\n",
    "# images = np.exp(3*images) / (1 + np.exp(3*images)) - 0.5\n",
    "images = (images - images.min()) / (images.max() - images.min())\n",
    "# images = np.load(\"data/mnist_test_seq_resized.npy\").swapaxes(0,1)\n",
    "print(images.shape, images.max(), images.min())\n",
    "shape = images.shape\n",
    "\n",
    "images = images.reshape(-1, 1, shape[-2], shape[-1])\n",
    "print(images.shape)\n",
    "N = shape[0]\n",
    "N_frames = shape[1]\n",
    "dt = 1./N_frames\n",
    "Num_pos_velocity = 1\n",
    "times = np.arange(0, N_frames*dt, dt)\n",
    "\n",
    "# dataset = [(image, 0) for image in dataset]\n",
    "# dataset = add_spatial_encoding(dataset)\n",
    "# print(len(dataset), len(dataset[0]), dataset[0][0].shape)\n",
    "images = torch.from_numpy(add_spatial_encoding(images)).float().reshape(N, -1, 3, HEIGHT, WIDTH)\n",
    "\n",
    "# split the dataset\n",
    "images_train, images_test = train_test_split(images, test_size=0.2, random_state=42)\n",
    "\n",
    "print(images_train.shape, images_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = np.random.randint(0, images_train.shape[1])\n",
    "# plt.imshow(ex0[index], cmap=\"gray\")\n",
    "# plt.show()\n",
    "# print(ex0.max(), ex0.min())\n",
    "# plt.imshow(ex1[index],cmap=\"gray\")\n",
    "# plt.show()\n",
    "# print(ex1.max(), ex1.min())\n",
    "# plt.imshow(np.abs(ex0[index] - ex1[index]),cmap=\"gray\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For 64x64 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Generating images...\n",
      "(7500, 20, 64, 64)\n",
      "(150000, 1, 64, 64)\n",
      "torch.Size([6000, 20, 3, 64, 64]) torch.Size([1500, 20, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "MARGIN_MIN = 7\n",
    "MIN_INIT_VELOCITY = 1000.\n",
    "WIDTH, HEIGHT = 64, 64\n",
    "RADIUS = 3\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"Generating images...\")\n",
    "images = np.load(\"data/mnist_test_seq.npy\").swapaxes(0,1)[:7500]\n",
    "\n",
    "images = (images - images.min()) / (images.max() - images.min())\n",
    "print(images.shape)\n",
    "shape = images.shape\n",
    "\n",
    "images = images.reshape(-1, 1, shape[-2], shape[-1])\n",
    "print(images.shape)\n",
    "N = shape[0]\n",
    "N_frames = shape[1]\n",
    "dt = 1./N_frames\n",
    "Num_pos_velocity = 1\n",
    "times = np.arange(0, N_frames*dt, dt)\n",
    "\n",
    "# dataset = [(image, 0) for image in dataset]\n",
    "# dataset = add_spatial_encoding(dataset)\n",
    "# print(len(dataset), len(dataset[0]), dataset[0][0].shape)\n",
    "images = torch.from_numpy(add_spatial_encoding(images)).float().reshape(N, -1, 3, HEIGHT, WIDTH)\n",
    "\n",
    "# split the dataset\n",
    "images_train, images_test = train_test_split(images, test_size=0.2, random_state=42)\n",
    "print(images_train.shape, images_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder and decoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 28x28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvEnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, device, dynamics_dim, appearance_dim, in_channels,\n",
    "                    activation=nn.ReLU(), relu=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.dynamics_dim = dynamics_dim\n",
    "        self.appearance_dim = appearance_dim\n",
    "        self.in_channels = in_channels\n",
    "        self.activation = activation\n",
    "        self.relu = relu\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=self.in_channels, out_channels=32, kernel_size=5, stride=2, padding=1),\n",
    "                    self.activation,\n",
    "                    # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2, padding=1),\n",
    "                    self.activation,\n",
    "                    # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1),\n",
    "                    self.activation\n",
    "                    # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.encoder_dynamics = nn.Sequential(\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(in_features=3*3*128, out_features=self.dynamics_dim),\n",
    "        )\n",
    "        self.encoder_appearance = nn.Sequential(\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(in_features=3*3*128, out_features=self.appearance_dim),\n",
    "        )\n",
    "        \n",
    "        # print the number of parameters in the model\n",
    "        print(\"Number of parameters in the encoder model: {}\".format(np.sum([p.numel() for p in self.parameters() if p.requires_grad])))\n",
    "\n",
    "\n",
    "    def forward(self, image):\n",
    "        # print(image.shape)\n",
    "        out = self.encoder(image)\n",
    "        # print(out.shape)\n",
    "        dyn = self.encoder_dynamics(out)\n",
    "        appearance = self.encoder_appearance(out)\n",
    "\n",
    "        # In order to apply the class TimeDistributed\n",
    "        # dyn: N x D, appearance: N x A\n",
    "        stacked_tensor = torch.cat((dyn, appearance), dim=-1)\n",
    "\n",
    "        return stacked_tensor\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, device, dynamics_dim, appearance_dim, in_channels,\n",
    "                    activation=nn.ReLU()):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.dynamics_dim = dynamics_dim\n",
    "        self.appearance_dim = appearance_dim\n",
    "        self.latent_dim = dynamics_dim + appearance_dim\n",
    "        self.in_channels = in_channels\n",
    "        self.activation = activation\n",
    "\n",
    "        self.decoder_linear = nn.Sequential(\n",
    "                    nn.Linear(in_features=self.latent_dim, out_features=3*3*128),\n",
    "                    self.activation\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "                    nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=0),\n",
    "                    self.activation,\n",
    "                    nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=4, stride=2, padding=1),\n",
    "                    self.activation,\n",
    "                    nn.ConvTranspose2d(in_channels=32, out_channels=self.in_channels, kernel_size=4, stride=2, padding=1),\n",
    "                    nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # print the number of parameters in the model\n",
    "        print(\"Number of parameters in the decoder model: {}\".format(np.sum([p.numel() for p in self.parameters() if p.requires_grad])))\n",
    "\n",
    "    def forward(self, latent):\n",
    "\n",
    "        out = self.decoder_linear(latent)\n",
    "        # print(out.shape)\n",
    "        out = out.view(latent.shape[0], 128, 3, 3)\n",
    "        # print(out.shape)\n",
    "        out = self.decoder(out)\n",
    "        # print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResEnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class blockResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, intermediate_channels, \n",
    "        identity_downsample=None, stride=1, expansion=4\n",
    "    ):\n",
    "        super(blockResNet, self).__init__()\n",
    "        self.expansion = expansion\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels * self.expansion,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "        # print(\"-\"*70)\n",
    "        # print(\"Number of parameters: \", sum([p.numel() for p in self.parameters()]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetCustomEncoder(nn.Module):\n",
    "    def __init__(self, layers, image_channels, dynamics_dim=64,\n",
    "        appearance_dim=32, expansion=4):\n",
    "        super(ResNetCustomEncoder, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.dynamics_dim = dynamics_dim\n",
    "        self.appearance_dim = appearance_dim\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.expansion = expansion\n",
    "        self.block = blockResNet\n",
    "\n",
    "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
    "        self.layer1 = self._make_layer(\n",
    "        self.block, layers[0], intermediate_channels=32, stride=1\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "        self.block, layers[1], intermediate_channels=64, stride=2\n",
    "        )\n",
    "        # self.layer3 = self._make_layer(\n",
    "        # block, layers[2], intermediate_channels=64, stride=2\n",
    "        # )\n",
    "        # self.layer4 = self._make_layer(\n",
    "        # block, layers[3], intermediate_channels=128, stride=2\n",
    "        # )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(self.expansion * 64, dynamics_dim + appearance_dim)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # print(\"Number of parameters: \", sum([p.numel() for p in self.layer1.parameters()])/1000, \"k\")\n",
    "        # print(\"Number of parameters: \", sum([p.numel() for p in self.layer2.parameters()])/1000, \"k\")\n",
    "        # print(\"Number of parameters: \", sum([p.numel() for p in self.layer3.parameters()])/1000, \"k\")\n",
    "        # # print(\"Number of parameters: \", sum([p.numel() for p in self.layer4.parameters()])/1000, \"k\")\n",
    "        \n",
    "        print(\"Number of parameters: \", sum([p.numel() for p in self.parameters()])/1e6, \"M\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        # x = self.layer3(x)\n",
    "        # x = self.layer4(x)\n",
    "        x = self.avgpool(x)         # 1x1\n",
    "        x = torch.flatten(x, 1)     # remove 1 X 1 grid and make vector of tensor shape \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
    "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
    "        # to the layer that's ahead\n",
    "\n",
    "\n",
    "        if stride != 1 or self.in_channels != intermediate_channels * self.expansion:\n",
    "            identity_downsample = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "            self.in_channels,\n",
    "            intermediate_channels * self.expansion,\n",
    "            kernel_size=1,\n",
    "            stride=stride,\n",
    "            bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(intermediate_channels * self.expansion),\n",
    "            )\n",
    "\n",
    "            layers.append(\n",
    "            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
    "            )\n",
    "\n",
    "        # The expansion size is always 4 for ResNet 50,101,152\n",
    "        self.in_channels = intermediate_channels * self.expansion\n",
    "\n",
    "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
    "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
    "        # and also same amount of channels.\n",
    "        for _ in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, intermediate_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "class ResNetCustomDecoder(nn.Module):\n",
    "\tdef __init__(self, img_channel=3, n_latent=128):\n",
    "\t\tsuper(ResNetCustomDecoder,self).__init__()\n",
    "\t\tself.img_channel = img_channel\n",
    "\t\tself.n_latent = n_latent\n",
    "\t\tself.conv_shape = (256, 1, 1)\n",
    "\t\tprods = self.conv_shape[0] * self.conv_shape[1] * self.conv_shape[2]\n",
    "\t\tself.dfc2 = nn.Linear(n_latent, prods)\n",
    "\t\tself.bn2 = nn.BatchNorm1d(prods)\n",
    "\t\tself.dfc1 = nn.Linear(prods, prods)\n",
    "\t\tself.bn1 = nn.BatchNorm1d(prods)\n",
    "\t\tself.upsample1=nn.Upsample(scale_factor=2)\n",
    "\t\tself.dconv5 = nn.ConvTranspose2d(self.conv_shape[0], 128, 3, padding = 0)\n",
    "\t\tself.dconv4 = nn.ConvTranspose2d(128, 64, 3, padding = 1)\n",
    "\t\tself.dconv3 = nn.ConvTranspose2d(64, 32, 3, padding = 1)\n",
    "\t\tself.dconv2 = nn.ConvTranspose2d(32, 16, 4, padding = 2)\n",
    "\t\tself.dconv1 = nn.ConvTranspose2d(16, img_channel, 6, stride = 2, padding = 2)\n",
    "\n",
    "\t\tprint(\"Number of parameters in decoder: \", sum([p.numel() for p in self.parameters()])/1e6, \"M\")\n",
    "\t\t# for p in self.parameters():\n",
    "\t\t# \tprint(p.numel())\n",
    "\n",
    "\tdef forward(self,x):#,i1,i2,i3):\n",
    "\t\tbatch_size = x.size(0)\n",
    "\t\t# print(x.size())\n",
    "\t\tx = self.dfc2(x)\n",
    "\t\tx = F.relu(self.bn2(x))\n",
    "\t\t# print(x.size())\n",
    "\t\t#x = F.relu(x)\n",
    "\t\tx = self.dfc1(x)\n",
    "\t\tx = F.relu(self.bn1(x))\n",
    "\t\t# print(x.size())\n",
    "\t\t#x = F.relu(x)\n",
    "\t\t# print(x.size())\n",
    "\n",
    "\t\tx = x.view(batch_size,self.conv_shape[0],self.conv_shape[1],self.conv_shape[2])\n",
    "\t\t# print (x.size())\n",
    "\t\tx=self.upsample1(x)\n",
    "\t\t# print(x.size())\n",
    "\t\tx = self.dconv5(x)\n",
    "\t\t# print(x.size())\n",
    "\t\tx = F.relu(x)\n",
    "\t\t# print(x.size())\n",
    "\t\tx = F.relu(self.dconv4(x))\n",
    "\t\t# print(x.size())\n",
    "\t\tx = F.relu(self.dconv3(x))\n",
    "\t\t# print(x.size())\n",
    "\t\tx=self.upsample1(x)\n",
    "\t\t# print(x.size())\n",
    "\t\tx = self.dconv2(x)\n",
    "\t\t# print(x.size())\n",
    "\t\tx = F.relu(x)\n",
    "\t\tx=self.upsample1(x)\n",
    "\t\t# print(x.size())\n",
    "\t\tx = self.dconv1(x)\n",
    "\t\t# print(x.size())\n",
    "\t\tx = torch.sigmoid(x)\n",
    "\t\t#print x\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, device, dynamics_dim, appearance_dim, in_channels,\n",
    "                    activation=nn.ReLU(), relu=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.device = device\n",
    "        # self.latent_dim = latent_dim\n",
    "        self.dynamics_dim = dynamics_dim\n",
    "        self.appearance_dim = appearance_dim\n",
    "        self.in_channels = in_channels\n",
    "        self.activation = activation\n",
    "        self.relu = relu\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            # first block\n",
    "                    nn.Conv2d(in_channels=self.in_channels, out_channels=64, kernel_size=3, stride=1, padding=0),\n",
    "                    self.activation,\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=0),\n",
    "                    self.activation,\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # second block\n",
    "                    nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=0),\n",
    "                    self.activation,\n",
    "                    nn.BatchNorm2d(128),\n",
    "                    # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=0),\n",
    "                    self.activation,\n",
    "                    nn.BatchNorm2d(128),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # third block\n",
    "                    nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=0),\n",
    "                    self.activation,\n",
    "                    nn.BatchNorm2d(256),\n",
    "                    # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=0),\n",
    "                    self.activation,\n",
    "                    nn.BatchNorm2d(256),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        ).to(device)\n",
    "        \n",
    "                    # nn.Conv2d(in_channels=self.in_channels, out_channels=32, kernel_size=7, stride=2, padding=1),\n",
    "                    # self.activation,\n",
    "                    # # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    # nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=2, padding=1),\n",
    "                    # self.activation,\n",
    "                    # # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    # nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1),\n",
    "                    # self.activation,\n",
    "                    # nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1),\n",
    "                    # self.activation,\n",
    "                    # nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=0),\n",
    "                    # self.activation\n",
    "                    # # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        self.encoder_dynamics = nn.Sequential(\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(in_features=256*4*4, out_features=self.dynamics_dim),\n",
    "        ).to(device)\n",
    "\n",
    "        self.encoder_appearance = nn.Sequential(\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(in_features=256*4*4, out_features=self.appearance_dim),\n",
    "        ).to(device)\n",
    "        \n",
    "        # print the number of parameters in the model\n",
    "        print(\"Number of parameters in the encoder model: {}\".format(np.sum([p.numel() for p in self.parameters() if p.requires_grad])))\n",
    "\n",
    "\n",
    "    def forward(self, image):\n",
    "        # print(\"Encoder, input image:\",image.shape)\n",
    "        out = self.encoder(image)\n",
    "        # print(\"Out of conv\", out.shape)\n",
    "        dyn = self.encoder_dynamics(out)\n",
    "        # stacked_tensor = dyn\n",
    "        appearance = self.encoder_appearance(out)\n",
    "\n",
    "        # # In order to apply the class TimeDistributed\n",
    "        # # dyn: N x D, appearance: N x A\n",
    "        stacked_tensor = torch.cat((dyn, appearance), dim=-1)\n",
    "\n",
    "        return stacked_tensor\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, device, dynamics_dim, appearance_dim, in_channels,\n",
    "                    activation=nn.ReLU()):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.dynamics_dim = dynamics_dim\n",
    "        self.appearance_dim = appearance_dim\n",
    "        # self.latent_dim = latent_dim\n",
    "        self.latent_dim = dynamics_dim + appearance_dim\n",
    "        self.in_channels = in_channels\n",
    "        self.activation = activation\n",
    "\n",
    "        self.decoder_linear = nn.Sequential(\n",
    "                    nn.Linear(in_features=self.latent_dim, out_features=256*4*4),\n",
    "                    self.activation\n",
    "        ).to(device)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # first block\n",
    "                    nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "                    nn.ConvTranspose2d(256, 128, kernel_size=3, stride=1, padding=0),\n",
    "                    self.activation,\n",
    "                    nn.BatchNorm2d(128),\n",
    "                    nn.ConvTranspose2d(128, 128, kernel_size=3, stride=1, padding=0),\n",
    "                    self.activation,\n",
    "                    nn.BatchNorm2d(128),\n",
    "\n",
    "            # second block\n",
    "                    nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "                    nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=0),\n",
    "                    self.activation,\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.ConvTranspose2d(64, 64, kernel_size=4, stride=1, padding=0),\n",
    "                    self.activation,\n",
    "                    nn.BatchNorm2d(64),\n",
    "            \n",
    "            # third block\n",
    "                    nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "                    nn.ConvTranspose2d(64, 32, kernel_size=4, stride=1, padding=0),\n",
    "                    self.activation,\n",
    "                    nn.BatchNorm2d(32),\n",
    "                    nn.ConvTranspose2d(32, 3, kernel_size=4, stride=1, padding=0),\n",
    "                    self.activation,\n",
    "                #     nn.BatchNorm2d(32),\n",
    "\n",
    "                #     nn.Conv2d(in_channels=32, out_channels=self.in_channels, kernel_size=1, stride=1, padding=1),\n",
    "                    nn.Sigmoid()\n",
    "                    \n",
    "\n",
    "                    \n",
    "        ).to(device)\n",
    "\n",
    "                    # nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=0),\n",
    "                    # self.activation,\n",
    "                    # nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, padding=1),\n",
    "                    # self.activation,\n",
    "                    # nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1),\n",
    "                    # self.activation,\n",
    "                    # nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=5, stride=2, padding=1),\n",
    "                    # self.activation,\n",
    "                    # nn.ConvTranspose2d(in_channels=32, out_channels=self.in_channels, kernel_size=7, stride=2, padding=0),\n",
    "                    # nn.Sigmoid()\n",
    "\n",
    "        # print the number of parameters in the model\n",
    "        print(\"Number of parameters in the decoder model: {}\".format(np.sum([p.numel() for p in self.parameters() if p.requires_grad])))\n",
    "\n",
    "    def forward(self, latent):\n",
    "\n",
    "        out = self.decoder_linear(latent)\n",
    "        # print(out.shape)\n",
    "        out = out.view(latent.shape[0], 256, 4, 4)\n",
    "        # print(out.shape)\n",
    "        out = self.decoder(out)\n",
    "        # print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Distributed class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module, len_shape_without_batch, batch_first=False):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "        self._len_shape_without_batch = len_shape_without_batch\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, time, *]\n",
    "        assert len(x.shape) == self._len_shape_without_batch or self._len_shape_without_batch + 1, f\"Input must have shape {self._len_shape_without_batch}D or {self._len_shape_without_batch + 1}D, received {len(x.shape)}D\"\n",
    "\n",
    "        if len(x.size()) == self._len_shape_without_batch:\n",
    "            return self.module(x)\n",
    "\n",
    "        batch_flatten_shapes = list(x.shape[1:])\n",
    "        batch_flatten_shapes[0] = -1\n",
    "        # Squash samples and timesteps into a single axis\n",
    "        x_reshape = x.contiguous().reshape(batch_flatten_shapes)  # (samples * timesteps, input_size)\n",
    "        # print(\"TimeDistributed: x_reshape: \", x_reshape.shape)\n",
    "        y = self.module(x_reshape)\n",
    "        # print(\"TimeDistributed: y: \", y.shape)\n",
    "\n",
    "        # We have to reshape Y\n",
    "        \n",
    "        if self.batch_first:\n",
    "            final_shapes = [x.shape[0], -1] + list(y.shape[1:])\n",
    "            y = y.contiguous().view(final_shapes)  # (samples, timesteps, output_size)\n",
    "        else:\n",
    "            final_shapes = [-1, x.shape[1]] + list(y.shape[1:])\n",
    "            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n",
    "        # print(\"TimeDistributed: y return: \", y.shape)\n",
    "\n",
    "\n",
    "        # print('TimeDistributed: y return: ', y.shape)    \n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNodeAppearance(nn.Module):\n",
    "    def __init__(self, device, size, dynamics_dim, appearance_dim, in_channels,\n",
    "    ode_hidden_dim, ode_out_dim, augment_dim=0, time_dependent=False, ode_linear_layer=False,\n",
    "    ode_non_linearity='relu', conv_activation=nn.ReLU(),latent_activation=None, stack_size=1):\n",
    "    \n",
    "        super(ConvNodeAppearance, self).__init__()\n",
    "        self.device = device\n",
    "        self.size = size\n",
    "        self.dynamics_dim = dynamics_dim\n",
    "        self.appearance_dim = appearance_dim\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_activation = conv_activation\n",
    "        self.latent_activation = latent_activation\n",
    "        self.ode_hidden_dim = ode_hidden_dim\n",
    "        self.out_dim = ode_out_dim\n",
    "        self.augment_dim = augment_dim\n",
    "        self.time_dependent = time_dependent\n",
    "        self.ode_linear_layer = ode_linear_layer\n",
    "        self.ode_non_linearity = ode_non_linearity\n",
    "        self.stack_size = stack_size\n",
    "\n",
    "        print(\"-\"*50)\n",
    "        print(\"Creating ConvAE...\")\n",
    "        self.encoder = TimeDistributed(\n",
    "            Encoder(device, dynamics_dim, appearance_dim, in_channels)\n",
    "            .to(device),\n",
    "            len_shape_without_batch=4, # input without batch are (times, latent_dim)\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.decoder = TimeDistributed(\n",
    "            Decoder(device, dynamics_dim, self.appearance_dim*(self.stack_size + 1), in_channels).to(device),\n",
    "            len_shape_without_batch=2, # input without batch are (times, latent_dim)\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        print(\"-\"*50)\n",
    "        print(\"Creating ANODENet...\")\n",
    "        self.node = ANODENet(device, dynamics_dim*(stack_size + 1), ode_hidden_dim, ode_out_dim, augment_dim, time_dependent=False,\n",
    "            non_linearity=ode_non_linearity, linear_layer=ode_linear_layer).to(device)\n",
    "\n",
    "    def forward(self, images, times, dt):\n",
    "        # images: [(batch), n_stack, in_channels, height, width]\n",
    "        # latent_z: [n_stack, latent_dim]\n",
    "        # print(\"input_images: \", images.shape)\n",
    "        latent_z = self.encoder(images)\n",
    "        # latent_dyn: [batch, n_stack, dynamics_dim]\n",
    "        # print(\"latent_z shape\", latent_z.shape)\n",
    "        latent_dynamics = latent_z[..., :self.dynamics_dim]\n",
    "        # print(\"latent_dynamics shape\", latent_dynamics.shape)\n",
    "        # latent_app: [batch, n_stack, appearance_dim]\n",
    "        latent_appearance = latent_z[..., self.dynamics_dim:].reshape(-1, 1, (self.stack_size + 1)*self.appearance_dim)\n",
    "        # debugging\n",
    "        # latent_appearance = torch.zeros_like(latent_appearance)\n",
    "        # print(latent_appearance)\n",
    "        # print(\"latent_appearance shape\", latent_appearance.shape)\n",
    "        # print(\"latent_z: \", latent_z.shape)\n",
    "        \n",
    "        # latent_z_stack: [(batch), n_stack, latent_dim*(n_stack+1)]\n",
    "        # for the moment n_stack = 1\n",
    "        if len(latent_dynamics.shape) == 3:\n",
    "            latent_z_stack = torch.cat([latent_dynamics[:, :-1], (latent_dynamics[:, 1:]-latent_dynamics[:, :-1])/dt], dim=-1).squeeze(1)\n",
    "        \n",
    "\n",
    "        elif len(latent_dynamics.shape) == 2:\n",
    "            latent_z_stack = torch.cat([latent_dynamics[:-1], (latent_dynamics[1:]-latent_dynamics[:-1])/dt], dim=-1)\n",
    "\n",
    "        # print(\"latent_z_stack: \", latent_z_stack.shape)\n",
    "\n",
    "        # sim : [times, (batch),ode_out_dim]\n",
    "        # print(\"latent_stacked shape\", latent_z_stack.shape)\n",
    "        sim = self.node(latent_z_stack, times)\n",
    "        # print(\"sim: \", sim.shape)\n",
    "        # sim : [(batch), n_stack, ode_out_dim]\n",
    "        if len(images.shape) == 5:\n",
    "            sim = sim.swapdims(0,1)\n",
    "        else:\n",
    "            sim = sim.squeeze(1)\n",
    "        # print(\"sim: \", sim.shape)\n",
    "\n",
    "        # add the latent_appearance to the sim to reconstruct\n",
    "        # print(\"sim shape\", sim.shape)\n",
    "        latent_appearance = latent_appearance.repeat(1, sim.shape[1], 1)\n",
    "        # print(\"appearance shape\", latent_appearance.shape)\n",
    "        latent_out = torch.cat([sim, latent_appearance], dim=-1)\n",
    "        # print(\"latent_out: \", latent_out.shape)\n",
    "        # print(latent_out)\n",
    "        reconstructed_images = self.decoder(latent_out)\n",
    "        # print(\"reconstructed_images: \", reconstructed_images.shape)\n",
    "\n",
    "        return reconstructed_images, sim\n",
    "\n",
    "    def encode(self, images):\n",
    "\n",
    "        return self.encoder(images)\n",
    "\n",
    "    def decode(self, latent_z):\n",
    "        return self.decoder(latent_z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNodeAppearance(nn.Module):\n",
    "    def __init__(self, device, size, layers, dynamics_dim, appearance_dim, in_channels, out_channels,\n",
    "    ode_hidden_dim, ode_out_dim, augment_dim=0, time_dependent=False, ode_linear_layer=False,\n",
    "    ode_non_linearity='relu', conv_activation=nn.ReLU(),latent_activation=None, stack_size=1):\n",
    "    \n",
    "        super(ResNodeAppearance, self).__init__()\n",
    "        self.device = device\n",
    "        self.size = size\n",
    "        self.layers = layers\n",
    "        self.dynamics_dim = dynamics_dim\n",
    "        self.appearance_dim = appearance_dim\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_activation = conv_activation\n",
    "        self.latent_activation = latent_activation\n",
    "        self.ode_hidden_dim = ode_hidden_dim\n",
    "        self.out_dim = ode_out_dim\n",
    "        self.augment_dim = augment_dim\n",
    "        self.time_dependent = time_dependent\n",
    "        self.ode_linear_layer = ode_linear_layer\n",
    "        self.ode_non_linearity = ode_non_linearity\n",
    "        self.stack_size = stack_size\n",
    "\n",
    "        print(\"-\"*50)\n",
    "        print(\"Creating ConvAE...\")\n",
    "        self.encoder = ResNetCustomEncoder(layers, in_channels, dynamics_dim=2*dynamics_dim, appearance_dim=appearance_dim).to(device)\n",
    "            \n",
    "        self.decoder = TimeDistributed(\n",
    "            ResNetCustomDecoder(img_channel=out_channels, n_latent=dynamics_dim + self.appearance_dim).to(device),\n",
    "            len_shape_without_batch=2, # input without batch are (times, latent_dim)\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        print(\"-\"*50)\n",
    "        print(\"Creating ANODENet...\")\n",
    "        self.node = ANODENet(device, 2*dynamics_dim, ode_hidden_dim, ode_out_dim, augment_dim, time_dependent=False,\n",
    "            non_linearity=ode_non_linearity, linear_layer=ode_linear_layer).to(device)\n",
    "\n",
    "    def forward(self, image_inputs, times, dt):\n",
    "        # images: [(batch), n_stack, in_channels, height, width]\n",
    "        # latent_z: [n_stack, latent_dim]\n",
    "        # print(\"input_images: \", images.shape)\n",
    "        latent_z = self.encoder(image_inputs)\n",
    "        # latent_dyn: [batch, n_stack, dynamics_dim]\n",
    "        # print(\"latent_z shape\", latent_z.shape)\n",
    "        latent_dynamics = latent_z[..., :2*self.dynamics_dim]\n",
    "        # print(\"latent_dynamics shape\", latent_dynamics.shape)\n",
    "        # latent_app: [batch, n_stack, appearance_dim]\n",
    "        latent_appearance = latent_z[..., 2*self.dynamics_dim:].unsqueeze(1)\n",
    "        # debugging\n",
    "        # latent_appearance = torch.zeros_like(latent_appearance)\n",
    "        # print(latent_appearance)\n",
    "        # print(\"latent_appearance shape\", latent_appearance.shape)\n",
    "        # print(\"latent_z: \", latent_z.shape)\n",
    "        \n",
    "        # latent_z_stack: [(batch), n_stack, latent_dim*(n_stack+1)]\n",
    "\n",
    "        # print(\"latent_z_stack: \", latent_z_stack.shape)\n",
    "\n",
    "        # sim : [times, (batch),ode_out_dim]\n",
    "        # print(\"latent_stacked shape\", latent_z_stack.shape)\n",
    "        # print(\"latent_dynamics shape\", latent_dynamics.shape)\n",
    "        # print(\"latent_appearance shape\", latent_appearance.shape)\n",
    "        sim = self.node(latent_dynamics, times)\n",
    "        # print(\"sim shape\", sim.shape)\n",
    "        # print(\"sim: \", sim.shape)\n",
    "        # sim : [(batch), n_stack, ode_out_dim]\n",
    "        if len(image_inputs.shape) == 4:\n",
    "            sim = sim.swapdims(0,1)\n",
    "        else:\n",
    "            sim = sim.squeeze(1)\n",
    "        # print(\"sim: \", sim.shape)\n",
    "\n",
    "        # add the latent_appearance to the sim to reconstruct\n",
    "        # print(\"sim shape\", sim.shape)\n",
    "        # print(\"before\", latent_appearance.shape)\n",
    "        latent_appearance = latent_appearance.repeat(1, sim.shape[1], 1)\n",
    "        # print(\"appearance shape\", latent_appearance.shape)\n",
    "        # print(\"after shape\", latent_appearance.shape)\n",
    "        # print(\"dynamics\", sim.shape)\n",
    "\n",
    "        latent_out = torch.cat([sim, latent_appearance], dim=-1)\n",
    "\n",
    "        # print(\"latent_out: \", latent_out.shape)\n",
    "        # print(latent_out)\n",
    "        reconstructed_images = self.decoder(latent_out)\n",
    "        # print(\"reconstructed_images: \", reconstructed_images.shape)\n",
    "\n",
    "        return reconstructed_images, sim\n",
    "\n",
    "    def forward_diff_appearance(self, images_dyn, images_app, times, dt):\n",
    "        # Dynamics\n",
    "        latent_z_dyn = self.encoder(images_dyn)\n",
    "        latent_dynamics = latent_z_dyn[..., :2*self.dynamics_dim]\n",
    "        \n",
    "        # Appearance\n",
    "        latent_z_app = self.encoder(images_app)\n",
    "        latent_appearance = latent_z_app[..., 2*self.dynamics_dim:].unsqueeze(1)\n",
    "        \n",
    "        # latent_z_stack: [(batch), n_stack, latent_dim*(n_stack+1)]\n",
    "        # for the moment n_stack = 1\n",
    "        # if len(latent_dynamics.shape) == 3:\n",
    "        #     latent_z_stack = torch.cat([latent_dynamics[:, :-1], (latent_dynamics[:, 1:]-latent_dynamics[:, :-1])/dt], dim=-1).squeeze(1)\n",
    "        \n",
    "\n",
    "        # elif len(latent_dynamics.shape) == 2:\n",
    "        #     latent_z_stack = torch.cat([latent_dynamics[:-1], (latent_dynamics[1:]-latent_dynamics[:-1])/dt], dim=-1)\n",
    "\n",
    "        # print(\"latent_z_stack: \", latent_z_stack.shape)\n",
    "\n",
    "        # sim : [times, (batch),ode_out_dim]\n",
    "        # print(\"latent_stacked shape\", latent_z_stack.shape)\n",
    "        sim = self.node(latent_dynamics, times)\n",
    "        # print(\"sim: \", sim.shape)\n",
    "        # sim : [(batch), n_stack, ode_out_dim]\n",
    "        if len(images_dyn.shape) == 4:\n",
    "            sim = sim.swapdims(0,1)\n",
    "        else:\n",
    "            sim = sim.squeeze(1)\n",
    "        # print(\"sim: \", sim.shape)\n",
    "\n",
    "        # add the latent_appearance to the sim to reconstruct\n",
    "        # print(\"sim shape\", sim.shape)\n",
    "        latent_appearance = latent_appearance.repeat(1, sim.shape[1], 1)\n",
    "        # print(\"appearance shape\", latent_appearance.shape)\n",
    "        # print(\"latent_appearance shape\", latent_appearance.shape)\n",
    "        latent_out = torch.cat([sim, latent_appearance], dim=-1)\n",
    "        # print(\"latent_out: \", latent_out.shape)\n",
    "        # print(latent_out)\n",
    "        reconstructed_images = self.decoder(latent_out)\n",
    "        # print(\"reconstructed_images: \", reconstructed_images.shape)\n",
    "\n",
    "        return reconstructed_images, sim\n",
    "\n",
    "    def encode(self, images):\n",
    "\n",
    "        return self.encoder(images)\n",
    "\n",
    "    def decode(self, latent_z):\n",
    "        return self.decoder(latent_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appearance_dim:  128\n",
      "--------------------------------------------------\n",
      "Creating ConvAE...\n",
      "----------------------------------------------------------------------\n",
      "Number of parameters:  0.444928 M\n",
      "----------------------------------------------------------------------\n",
      "Number of parameters in decoder:  0.513459 M\n",
      "--------------------------------------------------\n",
      "Creating ANODENet...\n",
      "Number of parameters in the model: 139968\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNodeAppearance:\n\tsize mismatch for encoder.fc.weight: copying a param with shape torch.Size([192, 256]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for encoder.fc.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder.module.dfc2.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([256, 192]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1c79107b75d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pathConvODE = \"ssh/resnet_modified_ode_one_digit_moving_mnist_dyn_latent_64_app_dim_64_hidden_ode_256_stack_1_conv_activation_ReLU().pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mpathConvODE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ssh/resnet_modified_ode_new_one_digit_moving_mnist_dyn_latent_64_app_dim_64_hidden_ode_256_stack_1_conv_activation_ReLU().pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mconv_ode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathConvODE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1483\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNodeAppearance:\n\tsize mismatch for encoder.fc.weight: copying a param with shape torch.Size([192, 256]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for encoder.fc.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder.module.dfc2.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([256, 192])."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "size = 28\n",
    "layers = [3, 4, 6, 3]\n",
    "dynamics_dim = 64\n",
    "appearance_dim = 128\n",
    "print(\"appearance_dim: \", appearance_dim)\n",
    "in_channels = 4\n",
    "out_channels = 3\n",
    "ode_data_dim = dynamics_dim\n",
    "ode_hidden_dim = 256\n",
    "augment_dim = 0\n",
    "time_dependent=False\n",
    "ode_non_linearity='relu' \n",
    "conv_activation=nn.ReLU()\n",
    "latent_activation=None\n",
    "stack_size=1\n",
    "\n",
    "conv_ode = ResNodeAppearance(device, size, layers, dynamics_dim, appearance_dim, in_channels,\n",
    "    out_channels, ode_hidden_dim, dynamics_dim, augment_dim=0, time_dependent=False, ode_linear_layer=False,\n",
    "    ode_non_linearity='relu', conv_activation=nn.ReLU(),latent_activation=None, stack_size=1)\n",
    "\n",
    "# pathConvODE = \"ssh/conv_ode_moving_mnist_dyn_latent_{}_app_dim_{}_hidden_ode_{}_stack_{}_conv_activation_{}.pt\".format(dynamics_dim, appearance_dim, ode_hidden_dim, stack_size, conv_activation)\n",
    "# pathConvODE = \"ssh/resnet_modified_ode_one_digit_moving_mnist_dyn_latent_64_app_dim_64_hidden_ode_256_stack_1_conv_activation_ReLU().pt\"\n",
    "pathConvODE = \"ssh/resnet_modified_ode_new_one_digit_moving_mnist_dyn_latent_64_app_dim_64_hidden_ode_256_stack_1_conv_activation_ReLU().pt\"\n",
    "conv_ode.load_state_dict(torch.load(pathConvODE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  torch.Size([32, 4, 28, 28])\n",
      "torch.Size([32, 20, 3, 28, 28]) torch.Size([32, 20, 64])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.zeros(32, 4, size, size)\n",
    "inputs = inputs.to(device)\n",
    "print(\"inputs: \", inputs.shape)\n",
    "times = torch.arange(0, 1, dt).to(device)\n",
    "reconstructed_images, sim = conv_ode(inputs, times, dt)\n",
    "reconstructed_images, sim = conv_ode.forward_diff_appearance(inputs, inputs, times, dt)\n",
    "print(reconstructed_images.shape, sim.shape)\n",
    "# print(reconstructed_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGetterMultiImages:\n",
    "    def __init__(self, batch_time, batch_size, n_stack, total_length, dt, images, frac_train):\n",
    "        # N: number of trajectories\n",
    "        # M: number of time steps\n",
    "        # D: dimension of the state space\n",
    "        # positions: (N, T, D)\n",
    "        self.times = torch.linspace(0., total_length*dt, total_length, dtype=torch.float64).float()\n",
    "        if isinstance(images, torch.Tensor):\n",
    "            self.true_images = images.float()\n",
    "\n",
    "        elif isinstance(images, np.ndarray):\n",
    "            self.true_images = torch.from_numpy(images).float()\n",
    "\n",
    "        else:\n",
    "            assert False, \"positions must be either a torch.Tensor or a np.ndarray\"\n",
    "\n",
    "        self.N_train = int(images.shape[0]*frac_train)\n",
    "\n",
    "        self.train_times = self.times #[:self.N_train]\n",
    "        self.test_times = self.times #[self.N_train:]\n",
    "        self.train_images = self.true_images[:self.N_train]\n",
    "        self.test_images = self.true_images[self.N_train:]\n",
    "        self.batch_size = batch_size\n",
    "        self.n_stack = n_stack\n",
    "        self.batch_time = batch_time\n",
    "        self.dt = dt\n",
    "        self.total_length = total_length\n",
    "\n",
    "    \n",
    "    def get_batch(self):\n",
    "        index = np.random.randint(0, self.N_train, self.batch_size)\n",
    "        s = torch.from_numpy(np.random.choice(np.arange(self.train_times.shape[0] - self.batch_time, dtype=np.int64), 1, replace=False))\n",
    "        batch_y0 = self.train_images[index, s:s+self.n_stack+1].squeeze(0) # (M, D)\n",
    "        batch_y0 = torch.cat([batch_y0[:, 0, 0].unsqueeze(1), batch_y0[:, 1, 0].unsqueeze(1), batch_y0[:, 1, 1].unsqueeze(1), batch_y0[:, 1, 2].unsqueeze(1)], dim=1)\n",
    "        batch_t = self.train_times[:self.batch_time]  # (T)\n",
    "        batch_y = torch.stack([self.train_images[index, s + i] for i in range(self.batch_time)], dim=1).squeeze(1)  # (T, M, D)\n",
    "        return batch_y0, batch_t, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Creating tools to train...\n",
      "y0:  torch.Size([64, 4, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*50)\n",
    "print(\"Creating tools to train...\")\n",
    "batch_size = 64\n",
    "batch_time = 18\n",
    "n_stack = 1\n",
    "total_length = N_frames - Num_pos_velocity\n",
    "\n",
    "getter = BatchGetterMultiImages(batch_time, batch_size, n_stack, total_length, dt, images_train, frac_train=1.)\n",
    "y0, times, _ = getter.get_batch()\n",
    "print(\"y0: \", y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.convnode import TimeDistributed\n",
    "\n",
    "class LatentRegularizerLoss(nn.Module):\n",
    "    def __init__(self, device, reg_lambda, step_decay=1, decay_rate=0.9, weighted=False, image_loss=None):\n",
    "        super(LatentRegularizerLoss, self).__init__()\n",
    "        self.device = device\n",
    "        self.reg_lambda = reg_lambda\n",
    "\n",
    "        if image_loss is None:\n",
    "            self.image_loss = nn.MSELoss()\n",
    "\n",
    "        elif not isinstance(image_loss, nn.Module):\n",
    "            raise ValueError(\"reconstruction_loss must be a subclass of nn.Module\")\n",
    "            \n",
    "        else:\n",
    "            self.image_loss = image_loss\n",
    "\n",
    "        if weighted:\n",
    "            self.image_loss.__init__(reduction=\"none\")\n",
    "        else:\n",
    "            self.image_loss.__init__(reduction=\"mean\")\n",
    "        \n",
    "        self.step_decay = step_decay\n",
    "        self.decay_rate = decay_rate\n",
    "        self._step = 0\n",
    "        self.weighted = weighted\n",
    "\n",
    "    def forward(self, latent_z, pred_images, true_images):\n",
    "        # latent_z: [batch, latent_dim]\n",
    "        # pred_images: [batch, n_stack, in_channels, height, width]\n",
    "        # true_images: [batch, n_stack, in_channels, height, width]\n",
    "        loss_img = self.image_loss(pred_images, true_images)\n",
    "        # print(loss_img.shape)\n",
    "        if self.weighted:\n",
    "            weights = torch.linspace(0, 1, pred_images.shape[1]).to(device).repeat(loss_img.shape[0], 1)\n",
    "            # print(weights.shape)\n",
    "            # print(weights.shape)\n",
    "            # print(weights)\n",
    "            weights = (0.0 + 5 * weights)\n",
    "            # print(weights)\n",
    "            loss_img = loss_img.mean(dim=(2,3,4))*weights \n",
    "        loss_img = loss_img.mean(dim=-1).mean(dim=-1)\n",
    "\n",
    "        loss_reg = torch.linalg.norm(latent_z, ord=2, dim=-1).mean(dim=-1).mean(dim=-1)\n",
    "        # print(\"loss_img: \", loss_img)\n",
    "        # print(\"loss_reg: \", loss_reg)\n",
    "        return loss_img + self.reg_lambda * loss_reg\n",
    "    \n",
    "\n",
    "    def step(self):\n",
    "        self._step +=1\n",
    "        if self._step % self.step_decay == 0:\n",
    "            self.reg_lambda *= self.decay_rate\n",
    "            \n",
    "\n",
    "    def forward_print(self, latent_z, pred_images, true_images):\n",
    "        # latent_z: [batch, latent_dim]\n",
    "        # pred_images: [batch, n_stack, in_channels, height, width]\n",
    "        # true_images: [batch, n_stack, in_channels, height, width]\n",
    "        loss_img = self.image_loss(pred_images, true_images)\n",
    "\n",
    "        if self.weighted:\n",
    "            weights = torch.linspace(0, 1, pred_images.shape[1]).to(device).repeat(loss_img.shape[0], 1)\n",
    "            # print(weights.shape)\n",
    "            # print(weights.shape)\n",
    "            # print(weights)\n",
    "            weights = (0.1 + 2 * weights)\n",
    "            # print(weights)\n",
    "            loss_img_weighted = loss_img.mean(dim=(2,3,4))*weights \n",
    "            loss_img = loss_img.mean(dim=(2,3,4))\n",
    "\n",
    "        loss_reg = torch.linalg.norm(latent_z, ord=2, dim=-1).mean(dim=-1).mean(dim=-1)\n",
    "        print(\"-\"*30, \"Loss prints\", \"-\"*30)\n",
    "        print(\"loss_img unweighted: \", loss_img.mean(dim=-1).mean(dim=-1))\n",
    "        if self.weighted:\n",
    "            print(\"loss_img weighted: \", loss_img_weighted.mean(dim=-1).mean(dim=-1))\n",
    "        print(\"loss_reg: \", self.reg_lambda * loss_reg)\n",
    "        print(\"reg_lambda: \",self.reg_lambda)\n",
    "        print(\"-\"*73)\n",
    "        return None\n",
    "\n",
    "class FinalStateWeightingMSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FinalStateWeightingMSE, self).__init__()\n",
    "        # self.mse = TimeDistributedLoss(nn.MSELoss(),\n",
    "        #                     4\n",
    "        # )\n",
    "\n",
    "        self.mse = nn.MSELoss(reduction=\"none\")\n",
    "        \n",
    "    def forward(self, latent_z, pred_images, true_images):\n",
    "        # latent_z: [batch, latent_dim]\n",
    "        # pred_images: [batch, n_stack, in_channels, height, width]\n",
    "        # true_images: [batch, n_stack, in_channels, height, width]\n",
    "        loss_img = self.mse(pred_images, true_images).mean(dim=(2,3,4))\n",
    "        # print(loss_img.shape)\n",
    "        weights = torch.linspace(0, 1, pred_images.shape[1]).to(device).repeat(loss_img.shape[0], 1)\n",
    "        # print(weights.shape)\n",
    "        # print(weights)\n",
    "        weights = (0.0 + 2 * weights)\n",
    "        # print(weights)\n",
    "        loss_img = loss_img*weights\n",
    "        # print(loss_img)\n",
    "        return loss_img.mean(dim=-1).mean(dim=-1)\n",
    "\n",
    "    def step(self):\n",
    "        pass\n",
    "\n",
    "    def forward_print(self, latent_z, pred_images, true_images):\n",
    "        loss_img = self.mse(pred_images, true_images).mean(dim=(2,3,4))\n",
    "        # print(loss_img.shape)\n",
    "        weights = torch.linspace(0, 1, pred_images.shape[1]).to(device).repeat(loss_img.shape[0], 1)\n",
    "        # print(weights.shape)\n",
    "        # print(weights)\n",
    "        weights = (0.1 + 2 * weights)\n",
    "        # print(weights)\n",
    "        loss_img_weighted = loss_img*weights\n",
    "        # print(loss_img)\n",
    "        print(\"-\"*30, \"Loss prints\", \"-\"*30)\n",
    "        print(\"loss_img unweighted: \", loss_img.mean(dim=-1).mean(dim=-1))\n",
    "        print(\"loss_img weighted: \", loss_img_weighted.mean(dim=-1).mean(dim=-1))\n",
    "        print(\"-\"*73)\n",
    "        return loss_img_weighted.mean(dim=-1).mean(dim=-1), loss_img.mean(dim=-1).mean(dim=-1)\n",
    "\n",
    "\n",
    "optimizerEnc = torch.optim.Adam(conv_ode.encoder.parameters(), lr=1e-4)\n",
    "optimizerDec = torch.optim.Adam(conv_ode.decoder.parameters(), lr=1e-4)\n",
    "optimizerODE = torch.optim.Adam(conv_ode.node.parameters(), lr=1e-4) #1e-4)\n",
    "optimizers = [optimizerEnc, optimizerDec, optimizerODE]\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizerODE, step_size=5000, gamma=1.)\n",
    "\n",
    "reg_lambda = 1e-5\n",
    "loss_fn = LatentRegularizerLoss(device, reg_lambda, step_decay=3000, decay_rate=1.0, weighted=False, image_loss=nn.MSELoss())\n",
    "# 4.722366482869652e-05\n",
    "# Adam (\n",
    "# Parameter Group 0\n",
    "#     amsgrad: False\n",
    "#     betas: (0.9, 0.999)\n",
    "#     eps: 1e-08\n",
    "#     initial_lr: 0.0001\n",
    "#     lr: 1.667718169966658e-05\n",
    "#     weight_decay: 0\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_convnode_trajectory(i, model, out_display, getter, final_time, dt, root=None, name=None):\n",
    "    \n",
    "    device = model.device\n",
    "    model.eval()\n",
    "    print(\"The graphs at epoch {}\".format(i))\n",
    "    with torch.no_grad():\n",
    "        index = np.random.randint(0, getter.N_train)\n",
    "\n",
    "        times = torch.linspace(0, (final_time-1)*dt, final_time, dtype=torch.float64).float().to(device)\n",
    "\n",
    "        # Building all input states\n",
    "        ground_truth_input = []\n",
    "        for i in range(len(times)):\n",
    "            gd_test = getter.train_images[index, i:i+2].unsqueeze(0).to(device)\n",
    "            gd_test = torch.cat([gd_test[:, 0, 0].unsqueeze(1), gd_test[:, 1, 0].unsqueeze(1), gd_test[:, 1, 1].unsqueeze(1), gd_test[:, 1, 2].unsqueeze(1)], dim=1)\n",
    "            ground_truth_input.append(gd_test)\n",
    "\n",
    "        ground_truth_input = torch.stack(ground_truth_input, dim=0).squeeze(1).to(device)\n",
    "\n",
    "        input_test = torch.clone(ground_truth_input[0]).unsqueeze(0).to(device)\n",
    "        # print(input_test.shape)\n",
    "        # print(ground_truth_input.shape)\n",
    "\n",
    "        predicted_output, predicted_latent = model(input_test, times, dt)\n",
    "        predicted_output = predicted_output.squeeze(0)\n",
    "        predicted_latent = predicted_latent.squeeze(0)\n",
    "        # print(\"predicted_output: \", predicted_output.shape)\n",
    "        # print(\"predicted_latent: \", predicted_latent.shape)\n",
    "\n",
    "        # print(\"out_shape\", predicted_output.shape)\n",
    "        # print(\"sim_shape\", predicted_latent.shape)\n",
    "        pca_encoded_trajectory = predicted_latent[:, :out_display].cpu().detach().numpy()\n",
    "        # print(\"encoded\", pca_encoded_trajectory.shape)\n",
    "        # print(getter.train_positions[index].shape)\n",
    "        # print(\"train images\", getter.train_images[index, :-1, :out_display].shape)\n",
    "        pca_train_trajectory = model.encode(ground_truth_input).cpu().detach().numpy()[..., :out_display]\n",
    "        # print(\"encoded\", pca_encoded_trajectory.shape)\n",
    "        # print(\"train\", pca_train_trajectory.shape)\n",
    "        # print(\"train\",  pca_train_trajectory.shape)\n",
    "\n",
    "        if pca_encoded_trajectory.shape[-1] > 2:\n",
    "\n",
    "            # display in orange the predicted position and in blue the true position of the training set\n",
    "            pca = PCA(n_components=2).fit(pca_train_trajectory)\n",
    "            pca_encoded_trajectory = pca.transform(pca_encoded_trajectory)\n",
    "            # print(getter.train_positions[index].shape)\n",
    "            pca_train_trajectory = pca.transform(pca_train_trajectory)\n",
    "\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "        if pca_encoded_trajectory.shape[-1] > 1:\n",
    "            plt.subplot(2, 3, 2)\n",
    "            plt.plot(pca_encoded_trajectory[:,0], \n",
    "                    pca_encoded_trajectory[:,1], 'orange', label=\"Predicted\")\n",
    "\n",
    "            plt.plot(pca_train_trajectory[:,0], pca_train_trajectory[:,1], 'b', label=\"Ground truth\")\n",
    "\n",
    "            plt.xlabel(\"First coord\")\n",
    "            plt.ylabel(\"Second coord\")\n",
    "            plt.legend()\n",
    "            # plt.show()\n",
    "       \n",
    "\n",
    "        # print the X axis over the time\n",
    "        plt.subplot(2, 3, 1)\n",
    "        plt.plot(times.cpu().numpy(), pca_train_trajectory[:,0], 'r', label=\"Ground truth Coord 1\")\n",
    "        plt.plot(times.cpu().numpy(), pca_encoded_trajectory[:,0], 'orange', label=\"Predicted Coord 1\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"First coord of PCA\")\n",
    "        plt.legend()\n",
    "        # plt.show()\n",
    "\n",
    "        if pca_encoded_trajectory.shape[-1] > 1:\n",
    "            plt.subplot(2, 3, 3)\n",
    "            plt.plot(times.cpu().numpy(), pca_train_trajectory[:,1], 'r', label=\"Ground truth Coord 2\")\n",
    "            plt.plot(times.cpu().numpy(), pca_encoded_trajectory[:,1], 'orange', label=\"Predicted Coord 2\")\n",
    "            plt.xlabel(\"Time\")\n",
    "            plt.ylabel(\"Second coord of PCA\")\n",
    "            plt.legend()\n",
    "            # plt.show()\n",
    "\n",
    "        index_img = np.random.randint((getter.train_images.shape[1]-1)//4, getter.train_images.shape[1]-1)#(getter.train_images.shape[1]-1)//2, getter.train_images.shape[1]-1)\n",
    "        plt.subplot(2, 3, 4)\n",
    "        plt.imshow(getter.train_images[index, index_img, 0].cpu().numpy(), cmap='gray')\n",
    "        plt.title(f\"Image at time {index_img*dt:.3f}/{final_time*dt:.3f}\")\n",
    "        plt.subplot(2, 3, 6)\n",
    "        plt.imshow(predicted_output[index_img, 0].cpu().detach().numpy(), cmap=\"gray\")\n",
    "        plt.title(f\"Predicted image at time {index_img*dt:.3f}/{final_time*dt:.3f}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graphs at epoch 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "root = None #\"images/AE_ODE/Gravity/MultiTrajectories/Together/\"\n",
    "name = None # \"conv_ode_1_ball_latent_{}_hidden_ode_{}_stack_{}_conv_activation_{}\".format(latent_dim, ode_hidden_dim, stack_size, conv_activation)\n",
    "display_fn = lambda i, model, out_display, getter, final_time, dt: display_convnode_trajectory(i, model, out_display, getter, final_time, dt, root=root, name=name)\n",
    "display_fn(0, conv_ode, dynamics_dim, getter, N_frames - Num_pos_velocity, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 636/50000 [00:34<44:26, 18.52it/s, Loss: 0.00239256]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8982d36ff222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m train_convnode_with_batch(conv_ode, optimizers, scheduler, epochs,\n\u001b[0;32m---> 10\u001b[0;31m     getter, loss_fn=loss_fn, display=1000, display_results_fn=display_fn)\n\u001b[0m",
      "\u001b[0;32m~/perso/IntNeuralODE/src/utils/node.py\u001b[0m in \u001b[0;36mtrain_convnode_with_batch\u001b[0;34m(model, optimizers, scheduler, epochs, getter, display, loss_fn, display_results_fn, out_display)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# update the progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss: {loss.item():.8f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"-\"*50)\n",
    "print(\"Training...\")\n",
    "epochs = 50000\n",
    "\n",
    "# for param in conv_ode.node.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "\n",
    "train_convnode_with_batch(conv_ode, optimizers, scheduler, epochs,\n",
    "    getter, loss_fn=loss_fn, display=1000, display_results_fn=display_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(conv_ode.state_dict(), \"ssh/resnet_modified_ode_new_one_digit_moving_mnist_dyn_latent_{}_app_dim_{}_hidden_ode_{}_stack_{}_conv_activation_{}.pt\".format(dynamics_dim, appearance_dim, ode_hidden_dim, stack_size, conv_activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import gray2rgb\n",
    "\n",
    "def generate_interactive_plot(i, model, out_display, getter, final_time, dt, root=None, name=None):\n",
    "\n",
    "    index = np.random.randint(0, getter.N_train)\n",
    "    time_steps = np.linspace(0, final_time*dt, final_time)\n",
    "\n",
    "    times = torch.arange(0, final_time*dt, dt)\n",
    "\n",
    "    gd_images = []\n",
    "    for i in range(len(times)):\n",
    "        gd_test = getter.train_images[index, i:i+2].unsqueeze(0).to(device)\n",
    "        gd_test = torch.cat([gd_test[:, 0, 0].unsqueeze(1), gd_test[:, 1, 0].unsqueeze(1), gd_test[:, 1, 1].unsqueeze(1), gd_test[:, 1, 2].unsqueeze(1)], dim=1)\n",
    "        gd_images.append(gd_test)\n",
    "\n",
    "    gd_images = torch.stack(gd_images, dim=0).squeeze(1)\n",
    "    input_images = torch.clone(gd_images[0]).unsqueeze(0).to(device)\n",
    "    \n",
    "    gd_images = torch.clone(gd_images).cpu().numpy()\n",
    "    print(gd_images.shape, input_images.shape)\n",
    "\n",
    "    # print('input shape', input_images.shape)\n",
    "    # print('gd shape', gd_images.shape)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        reconstructed_images, _ = model(input_images.to(device), times.to(device), dt)\n",
    "        reconstructed_images = reconstructed_images.cpu().numpy()[0]\n",
    "\n",
    "    print(\"Sim\", reconstructed_images.shape, gd_images.shape)\n",
    "\n",
    "    # gd_images = np.expand_dims(gd_images, axis=1)\n",
    "    reconstructed_images = np.expand_dims(reconstructed_images[:,0], axis=1)\n",
    "    print(\"Extract Gray\", gd_images.shape, reconstructed_images.shape)\n",
    "\n",
    "    gd_images = np.array([gray2rgb(img[0]) for img in gd_images])\n",
    "    gd_images = 200*(gd_images - gd_images.min())/(gd_images.max() - gd_images.min())\n",
    "    print(\"Gray to rgb for gd_images\", gd_images.shape, reconstructed_images.shape)\n",
    "\n",
    "    reconstructed_images = np.array([gray2rgb(img[0]) for img in reconstructed_images])\n",
    "    reconstructed_images = 200*(reconstructed_images - reconstructed_images.min())/(reconstructed_images.max() - reconstructed_images.min())\n",
    "\n",
    "    print(\"Gray to rgb for reconstructed\", gd_images.shape, reconstructed_images.shape)\n",
    "\n",
    "    return interactive_part_trajectory_image_plot(gd_images, reconstructed_images, time_steps, dt)\n",
    "\n",
    "\n",
    "def interactive_part_trajectory_image_plot(inputs_images, reconstructed_images, time_steps, dt):\n",
    "    fig = make_subplots(rows=1, cols=3, subplot_titles=(\"Input image\", \"Predicted image\"))\n",
    "    fig = go.FigureWidget(fig)\n",
    "    # add a black background to the figure\n",
    "    fig.add_image(z=inputs_images[0], row=1, col=1, name='true image')\n",
    "    fig.add_image(z=reconstructed_images[0], row=1, col=2, name='predicted image')\n",
    "\n",
    "    N_max_input = len(inputs_images)-1\n",
    "    N_max_predicted = len(reconstructed_images)-1\n",
    "    N_max = max(N_max_input, N_max_predicted)\n",
    "\n",
    "    frac_input = 1. #N_max/N_max_predicted\n",
    "    frac_predicted = 1. #N_max/N_max_input\n",
    "\n",
    "    @interact(t=(time_steps.min(),time_steps.max(),dt))\n",
    "    def update_plot(t=0):\n",
    "        with fig.batch_update():\n",
    "            # change the current point of \n",
    "            print(t/dt)\n",
    "            print(int(frac_input*t/dt))\n",
    "            print(int(frac_predicted*t/dt))\n",
    "            fig.data[0].z = inputs_images[min(int(frac_input*t/dt), N_max_input)]\n",
    "            fig.data[1].z = reconstructed_images[min(int(frac_predicted*t/dt), N_max_predicted)]\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter_plot = BatchGetterMultiImages(batch_time, batch_size, n_stack, total_length, dt, images_test, frac_train=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 4, 28, 28) torch.Size([1, 4, 28, 28])\n",
      "Sim (19, 3, 28, 28) (19, 4, 28, 28)\n",
      "Extract Gray (19, 4, 28, 28) (19, 1, 28, 28)\n",
      "Gray to rgb for gd_images (19, 28, 28, 3) (19, 1, 28, 28)\n",
      "Gray to rgb for reconstructed (19, 28, 28, 3) (19, 28, 28, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d4c0ba0d3f4ff3b93e1712029609ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='t', max=0.9500000000000001, step=0.05), Output()), _…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f874d64e21d54a6ea4e81386c7a7c911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'name': 'true image',\n",
       "              'type': 'image',\n",
       "              'uid': 'b712a5…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = generate_interactive_plot(0, conv_ode, 0, getter_plot, int(1.*(N_frames - Num_pos_velocity)), dt, root=None, name=None)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appearance changement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import gray2rgb\n",
    "\n",
    "def generate_interactive_plot_appearance_swap(i, model, out_display, getter, final_time, dt, root=None, name=None):\n",
    "\n",
    "    index_dyn = np.random.randint(0, getter.N_train)\n",
    "    index_app = np.random.randint(0, getter.N_train)\n",
    "    time_steps = np.linspace(0, final_time*dt, final_time)\n",
    "\n",
    "    times = torch.arange(0, final_time*dt, dt)\n",
    "\n",
    "    \n",
    "    gd_images_dyn = []\n",
    "    for i in range(len(times)):\n",
    "        gd_test = getter.train_images[index_dyn, i:i+2].unsqueeze(0).to(device)\n",
    "        gd_test = torch.cat([gd_test[:, 0, 0].unsqueeze(1), gd_test[:, 1, 0].unsqueeze(1), gd_test[:, 1, 1].unsqueeze(1), gd_test[:, 1, 2].unsqueeze(1)], dim=1)\n",
    "        gd_images_dyn.append(gd_test)\n",
    "\n",
    "    gd_images_dyn = torch.stack(gd_images_dyn, dim=0).squeeze(1)\n",
    "    input_images_dyn = torch.clone(gd_images_dyn[0]).unsqueeze(0).to(device)\n",
    "    gd_images_dyn = gd_images_dyn.cpu().numpy()\n",
    "\n",
    "    gd_images_app = []\n",
    "    for i in range(len(times)):\n",
    "        gd_test = getter.train_images[index_app, i:i+2].unsqueeze(0).to(device)\n",
    "        gd_test = torch.cat([gd_test[:, 0, 0].unsqueeze(1), gd_test[:, 1, 0].unsqueeze(1), gd_test[:, 1, 1].unsqueeze(1), gd_test[:, 1, 2].unsqueeze(1)], dim=1)\n",
    "        gd_images_app.append(gd_test)\n",
    "\n",
    "    gd_images_app = torch.stack(gd_images_app, dim=0).squeeze(1)\n",
    "    input_images_app = torch.clone(gd_images_app[0]).unsqueeze(0).to(device)\n",
    "    gd_images_app = gd_images_app.cpu().numpy()\n",
    "\n",
    "    \n",
    "    \n",
    "    # print('input shape', input_images.shape)\n",
    "    # print('gd shape', gd_images.shape)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # reconstructed_images_dyn, _ = model(input_images_dyn.to(device), times.to(device), dt)\n",
    "        # reconstructed_images_dyn = reconstructed_images_dyn.cpu().numpy()[0]\n",
    "        \n",
    "        # reconstructed_images_app, _ = model(input_images_app.to(device), times.to(device), dt)\n",
    "        # reconstructed_images_app = reconstructed_images_app.cpu().numpy()[0]\n",
    "\n",
    "        reconstructed_images_transformed, _ = model.forward_diff_appearance(input_images_dyn.to(device), input_images_app.to(device), times.to(device), dt)\n",
    "        reconstructed_images_transformed = reconstructed_images_transformed.cpu().numpy()[0]\n",
    "    \n",
    "    # print(\"Sim\", reconstructed_images.shape, gd_images.shape)\n",
    "\n",
    "\n",
    "    # reconstructed_images_dyn = np.expand_dims(reconstructed_images_dyn[:,0], axis=1)\n",
    "    # reconstructed_images_app = np.expand_dims(reconstructed_images_app[:,0], axis=1)\n",
    "    reconstructed_images_transformed = np.expand_dims(reconstructed_images_transformed[:,0], axis=1)\n",
    "\n",
    "    \n",
    "    # print(\"Extract Gray\", gd_images.shape, reconstructed_images.shape)\n",
    "\n",
    "    gd_images_dyn = np.array([gray2rgb(img[0]) for img in gd_images_dyn])\n",
    "    gd_images_dyn = 200*(gd_images_dyn - gd_images_dyn.min())/(gd_images_dyn.max() - gd_images_dyn.min())\n",
    "\n",
    "    gd_images_app = np.array([gray2rgb(img[0]) for img in gd_images_app])\n",
    "    gd_images_app = 200*(gd_images_app - gd_images_app.min())/(gd_images_app.max() - gd_images_app.min())\n",
    "    # print(\"Gray to rgb for gd_images\", gd_images.shape, reconstructed_images.shape)\n",
    "\n",
    "    # reconstructed_images_dyn = np.array([gray2rgb(img[0]) for img in reconstructed_images_dyn])\n",
    "    # reconstructed_images_dyn = 200*(reconstructed_images_dyn - reconstructed_images_dyn.min())/(reconstructed_images_dyn.max() - reconstructed_images_dyn.min())\n",
    "\n",
    "    # reconstructed_images_app = np.array([gray2rgb(img[0]) for img in reconstructed_images_app])\n",
    "    # reconstructed_images_app = 200*(reconstructed_images_app - reconstructed_images_app.min())/(reconstructed_images_app.max() - reconstructed_images_app.min())\n",
    "    \n",
    "    reconstructed_images_transformed = np.array([gray2rgb(img[0]) for img in reconstructed_images_transformed])\n",
    "    reconstructed_images_transformed = 200*(reconstructed_images_transformed - reconstructed_images_transformed.min())/(reconstructed_images_transformed.max() - reconstructed_images_transformed.min())\n",
    "\n",
    "\n",
    "    # print(\"Gray to rgb for reconstructed\", gd_images.shape, reconstructed_images.shape)\n",
    "\n",
    "    return interactive_image_plot_appearance_swap(reconstructed_images_transformed, gd_images_dyn, gd_images_app, time_steps, dt)\n",
    "\n",
    "\n",
    "def interactive_image_plot_appearance_swap(reconstructed_images_transformed, \n",
    "                                            gd_images_dyn, gd_images_app, time_steps, dt):\n",
    "    fig = make_subplots(rows=1, cols=3, subplot_titles=[\"GT First trajectory\", \"Dynamic: 1st trajectory | Appearance: 2nd trajectory\", \"GT Second trajectory\"])\n",
    "    fig = go.FigureWidget(fig)\n",
    "    # add a black background to the figure\n",
    "    fig.add_image(z=gd_images_dyn[0], row=1, col=1, name='First trajectory')\n",
    "    fig.add_image(z=reconstructed_images_transformed[0], row=1, col=2, name='Dynamic: 1st trajectory | Appearance: 2nd trajectory')\n",
    "    fig.add_image(z=gd_images_app[0], row=1, col=3, name='Second trajectory')\n",
    "\n",
    "\n",
    "    N_max = len(reconstructed_images_transformed)-1\n",
    "\n",
    "    # should be initialized at zero\n",
    "    @interact(t=(time_steps.min(),time_steps.max(),dt), )\n",
    "    def update_plot(t=0.):\n",
    "        with fig.batch_update():\n",
    "            # change the current point of \n",
    "            print(\"float time ration\", t/dt)\n",
    "            print(\"int time ration\", int(t/dt))\n",
    "            index = min(int(t/dt), N_max)\n",
    "            fig.data[0].z = gd_images_dyn[index]\n",
    "            fig.data[1].z = reconstructed_images_transformed[index]\n",
    "            fig.data[2].z = gd_images_app[index]\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter_plot = BatchGetterMultiImages(batch_time, batch_size, n_stack, total_length, dt, images_train, frac_train=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54113478a32b40239f4d253225cb2783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='t', max=0.9500000000000001, step=0.05), Output()), _…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03dc943e68c9423db030d91b9b9837e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'name': 'First trajectory',\n",
       "              'type': 'image',\n",
       "              'uid': '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = generate_interactive_plot_appearance_swap(0, conv_ode, 0, getter_plot, int(1.*(N_frames - Num_pos_velocity)), dt, root=None, name=None)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
